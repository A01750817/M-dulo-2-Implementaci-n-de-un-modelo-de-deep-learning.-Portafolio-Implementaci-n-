{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fec68ab",
   "metadata": {},
   "source": [
    "## EXTRACION DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0614c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SPARTAN PC\\miniconda3\\envs\\langchain_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 621805568 bytes (1841559867 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/paultimothymooney/chest-xray-pneumonia?dataset_version_number=2 (621805568/2463365435) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 2.29G/2.29G [03:27<00:00, 8.87MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\SPARTAN PC\\.cache\\kagglehub\\datasets\\paultimothymooney\\chest-xray-pneumonia\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "base_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a raw string to avoid interpreting backslashes as escape sequences\n",
    "base_path = r\"C:\\Users\\SPARTAN PC\\.cache\\kagglehub\\datasets\\paultimothymooney\\chest-xray-pneumonia\\versions\\2\\chest_xray\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d64bb",
   "metadata": {},
   "source": [
    "## ESTRUCTURA DE LOS DIRECTORIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0735347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/\n",
      "  chest_xray/\n",
      "    test/\n",
      "      NORMAL/\n",
      "      PNEUMONIA/\n",
      "    test_val/\n",
      "      NORMAL/\n",
      "        IM-0001-0001.jpeg\n",
      "        IM-0003-0001.jpeg\n",
      "        IM-0005-0001.jpeg\n",
      "        ... y 239 archivos m치s\n",
      "      PNEUMONIA/\n",
      "        person100_bacteria_475.jpeg\n",
      "        person100_bacteria_477.jpeg\n",
      "        person100_bacteria_478.jpeg\n",
      "        ... y 395 archivos m치s\n",
      "    train/\n",
      "      NORMAL/\n",
      "        IM-0115-0001.jpeg\n",
      "        IM-0117-0001.jpeg\n",
      "        IM-0119-0001.jpeg\n",
      "        ... y 1338 archivos m치s\n",
      "      PNEUMONIA/\n",
      "        person1000_bacteria_2931.jpeg\n",
      "        person1000_virus_1681.jpeg\n",
      "        person1001_bacteria_2932.jpeg\n",
      "        ... y 3872 archivos m치s\n",
      "    val/\n",
      "      NORMAL/\n",
      "      PNEUMONIA/\n",
      "    __MACOSX/\n",
      "      ._chest_xray\n",
      "      chest_xray/\n",
      "        ._.DS_Store\n",
      "        ._test\n",
      "        ._train\n",
      "        test/\n",
      "          ._.DS_Store\n",
      "          ._NORMAL\n",
      "          ._PNEUMONIA\n",
      "          NORMAL/\n",
      "            ._IM-0001-0001.jpeg\n",
      "            ._IM-0003-0001.jpeg\n",
      "            ._IM-0005-0001.jpeg\n",
      "            ... y 231 archivos m치s\n",
      "          PNEUMONIA/\n",
      "            ._person100_bacteria_475.jpeg\n",
      "            ._person100_bacteria_477.jpeg\n",
      "            ._person100_bacteria_478.jpeg\n",
      "            ... y 387 archivos m치s\n",
      "        train/\n",
      "          ._.DS_Store\n",
      "          ._NORMAL\n",
      "          ._PNEUMONIA\n",
      "          NORMAL/\n",
      "            ._.DS_Store\n",
      "            ._IM-0115-0001.jpeg\n",
      "            ._IM-0117-0001.jpeg\n",
      "            ... y 1339 archivos m치s\n",
      "          PNEUMONIA/\n",
      "            ._.DS_Store\n",
      "            ._person1000_bacteria_2931.jpeg\n",
      "            ._person1000_virus_1681.jpeg\n",
      "            ... y 3873 archivos m치s\n",
      "        val/\n",
      "          ._.DS_Store\n",
      "          NORMAL/\n",
      "            ._.DS_Store\n",
      "            ._NORMAL2-IM-1427-0001.jpeg\n",
      "            ._NORMAL2-IM-1430-0001.jpeg\n",
      "            ... y 6 archivos m치s\n",
      "          PNEUMONIA/\n",
      "            ._.DS_Store\n",
      "            ._person1946_bacteria_4874.jpeg\n",
      "            ._person1946_bacteria_4875.jpeg\n",
      "            ... y 6 archivos m치s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    level = root.replace(base_path, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:3]:  # Mostrar solo los primeros 3 archivos\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 3:\n",
    "        print(f'{subindent}... y {len(files) - 3} archivos m치s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9bcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(base_path, \"chest_xray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be5559",
   "metadata": {},
   "source": [
    "### SEPARAMOS Y ANALISAMOS LA DISTRIBUCION DE IMAGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8afc5995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DISTRIBUCI칍N DE CLASES\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  NORMAL: 1341 im치genes\n",
      "  PNEUMONIA: 3875 im치genes\n",
      "\n",
      "TEST_VAL:\n",
      "  NORMAL: 242 im치genes\n",
      "  PNEUMONIA: 398 im치genes\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(path, 'train')\n",
    "test_val_path = os.path.join(path, 'test_val')\n",
    "\n",
    "class_counts = {}\n",
    "for split in ['train', 'test_val']:\n",
    "    split_path = os.path.join(path, split)\n",
    "    class_counts[split] = {}\n",
    "    for class_name in os.listdir(split_path):\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            class_counts[split][class_name] = count\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DISTRIBUCI칍N DE CLASES\")\n",
    "print(\"=\" * 50)\n",
    "for split, classes in class_counts.items():\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    for class_name, count in classes.items():\n",
    "        print(f\"  {class_name}: {count} im치genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed44dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "source = test_val_path\n",
    "\n",
    "target_test_path = os.path.join(path, \"test_new\")\n",
    "target_val_path = os.path.join(path, \"val_new\")\n",
    "targets = [target_test_path, target_val_path]\n",
    "\n",
    "os.makedirs(target_test_path, exist_ok=True)\n",
    "os.makedirs(target_val_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3f799",
   "metadata": {},
   "source": [
    "## Divisi칩n del conjunto TEST_VAL\n",
    "\n",
    "Tom칠 todas las im치genes del conjunto TEST_VAL y lo separ칠 nuevamente en dos partes: un conjunto de prueba (*test*) y un conjunto de validaci칩n (*val*). Us칠 una proporci칩n 80% para test y 20% para val porque es una divisi칩n com칰n cuando el conjunto de entrenamiento ya est치 definido.\n",
    "\n",
    "La separaci칩n se hizo por clase, no mezclando todo. As칤 se mantiene la relaci칩n original entre NORMAL y PNEUMONIA en cada split.\n",
    "\n",
    "Pasos:\n",
    "1. Mezcl칠 aleatoriamente las im치genes de cada clase.\n",
    "2. Separ칠 el 80% para test y el 20% para val.\n",
    "3. Copi칠 cada grupo en las carpetas nuevas `test_new/` y `val_new/`.\n",
    "\n",
    "Esto deja dos conjuntos equilibrados y listos para evaluaci칩n y validaci칩n del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for split in targets:\n",
    "    os.makedirs(os.path.join(split, 'PNEUMONIA'), exist_ok=True) #esto crea la carpeta pneumonia\n",
    "    os.makedirs(os.path.join(split, 'NORMAL'), exist_ok=True) #esto crea la carpeta normal\n",
    "\n",
    "random.seed(1337)  # Fija la semilla para que la divisi칩n sea reproducible\n",
    "\n",
    "for class_name in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "    class_path = os.path.join(source, class_name)\n",
    "    files = [f for f in os.listdir(class_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    total = len(files)\n",
    "    cut_off = int(0.8 * total)\n",
    "\n",
    "    test_files = files[:cut_off]\n",
    "    val_files = files[cut_off:]\n",
    "    # mover\n",
    "    for f in test_files:\n",
    "        shutil.copy2(os.path.join(class_path, f),\n",
    "                     os.path.join(target_test_path, class_name, f))\n",
    "        \n",
    "    for f in val_files:\n",
    "        shutil.copy2(os.path.join(class_path, f),\n",
    "                     os.path.join(target_val_path, class_name, f))\n",
    "        \n",
    "    print(\"Listo. Dividido en 80% test y 20% val.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6422a46c",
   "metadata": {},
   "source": [
    "Aqu칤 podemos ver que la distribuci칩n original del dataset se conserva: la proporci칩n entre NORMAL y PNEUMONIA es pr치cticamente la misma en los nuevos conjuntos. Esto es importante porque mantiene la representaci칩n del problema tal como aparece en el mundo real.  \n",
    "\n",
    "Adem치s, ahora contamos con suficientes im치genes tanto en `VAL_NEW` como en `TEST_NEW`, lo que facilita evaluar el modelo de forma confiable y verificar que realmente generaliza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f28ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DISTRIBUCI칍N DE CLASES\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  NORMAL: 1341 im치genes\n",
      "  PNEUMONIA: 3875 im치genes\n",
      "\n",
      "TEST_NEW:\n",
      "  NORMAL: 193 im치genes\n",
      "  PNEUMONIA: 318 im치genes\n",
      "\n",
      "VAL_NEW:\n",
      "  NORMAL: 49 im치genes\n",
      "  PNEUMONIA: 80 im치genes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class_counts = {}\n",
    "for split in ['train', 'test_new', 'val_new']:\n",
    "    split_path = os.path.join(path, split)\n",
    "    class_counts[split] = {}\n",
    "    for class_name in os.listdir(split_path):\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            class_counts[split][class_name] = count\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DISTRIBUCI칍N DE CLASES\")\n",
    "print(\"=\" * 50)\n",
    "for split, classes in class_counts.items():\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    for class_name, count in classes.items():\n",
    "        print(f\"  {class_name}: {count} im치genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990d296",
   "metadata": {},
   "source": [
    "## 游댧 Justificaci칩n de la Estrategia de Balanceo\n",
    "\n",
    "El *set* de entrenamiento presenta un **desbalance de clases significativo**, con una proporci칩n de $2.9$ im치genes de **Pneumon칤a** por cada imagen de **Normal**. Dado el limitado n칰mero de im치genes, aplicaremos un **Pipeline H칤brido** para mitigar los riesgos de **sobreajuste** y **sesgo**.\n",
    "\n",
    "---\n",
    "\n",
    "### Estrategia de Mitigaci칩n\n",
    "\n",
    "1.  **Data Augmentation Din치mico:**\n",
    "    * **Finalidad:** Se aplica Aumento de Datos din치mico (*on-the-fly*) al *dataset* de entrenamiento. Esta t칠cnica incrementa la **variedad** de la clase minoritaria (**Normal**), lo cual es crucial para prevenir el **sobreajuste** que podr칤a ocurrir al contar con tan pocas im치genes originales en esa clase.\n",
    "\n",
    "2.  **Ponderaci칩n de Clases:**\n",
    "    * **Finalidad:** Se implementa Ponderaci칩n de Clases (*Class Weighting*) en la funci칩n de p칠rdida. Esta decisi칩n es necesaria porque, a pesar de aplicar *Data Augmentation* a todo el *dataset*, el **sesgo de frecuencia** se mantiene en los *batches* de entrenamiento. La ponderaci칩n garantiza un aprendizaje m치s **equilibrado** al aumentar el peso de penalizaci칩n por error en la clase **Normal**.\n",
    "\n",
    "De esta manera, se ataca el desbalance desde el dominio de los datos (variedad) y desde el dominio algor칤tmico (importancia), sin la necesidad de reducir el tama침o del *dataset*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1c1f76",
   "metadata": {},
   "source": [
    "# 1. Comenzamos el pipeline del entrenamiento creando los generadores para los diferentes sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588c8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
